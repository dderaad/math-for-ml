{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dderaad/math-for-ml/blob/master/curriculum-2/JNJ_ML_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkszCfPmtovv"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Introduction:\n",
        "**Machine Learning** is an umbrella term for a wide variety of *supervised*, *unsupervised*, and *reinforcement* tasks where a computer synthesizes data to develop a model. Examples are regression, neural networks, decision trees, clustering methods, dimensionality reduction, etc.\n",
        "\n",
        "**Supervised Machine Learning**, and specifically **Classification** requires at least some of the *data* to be composed of observations with a pre-defined *class*. Each observation must also have explanatory variables from which a  **classification** can be learned.\n",
        "\n",
        "For example, we might want to predict a diagnosis for a patient based on a set of symptoms.\n",
        "\n",
        "The goal of *classification* is to take an observation with unknown class (outcome) and assign its class. A **classifier** is any algorithm (*e.g.* regression, decision trees) which can learn a mapping from observation to class.\n",
        "\n",
        "To continue our example, we have a dataset where we have patient covariate information (also called features or explanatory variables, such as age, height, sex, etc.) and symptoms they experienced. We also have a doctor's diagnosis based on these symptoms. We may use a decision tree to model the doctor's decisions and make predictions for patients that could not be seen by the doctor."
      ],
      "metadata": {
        "id": "wFWdKWI4tyDm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX7fjxGRtovy"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej9vb_WJtovz"
      },
      "source": [
        "The logistic regression typically models the probability of a class given an input. The most basic form of the logistic regression tries to make a binary choice, but also will model uncertainty (i.e. will output something in the range 0 to 1, not just 0 and 1). Here are some simple cases of image data where it may be difficult to distinguish the classes: ![](https://i.pinimg.com/originals/e3/bd/cb/e3bdcb19e8f72bf9392d935ba95092fa.jpg)\n",
        "\n",
        "![](https://prods3.imgix.net/images/articles/2016_03/Facebook-Dog-or-Chicken-Labradoodle-or-fried-chicken-puppy-or-bagel-Karen-Zwack-teeny-biscuit-memes.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98uDS5Bmtovz"
      },
      "source": [
        "One simple form of the model is the following: say that $p=P($image is a dog | image data$)$. Then a linear model could be given by $l = log(\\frac{p}{1-p}) = \\beta_0 + \\beta_1 x_1 + \\cdots$, where the $x$s may be pixels of the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSf2l0EQtov0"
      },
      "source": [
        "Unlike in the linear regression, we are trying to predict the probability of an outcome (class membership). As such, the $\\beta$ coefficients signify the contribution to the probability. While a positive $\\beta$ suggests that the pixel's intensity is related to the image being that of a dog, a negative $\\beta$ means that the pixel is related to the image being a croissant. Their magnitudes are only indicative of their contribution to the likelihood of the outcome. Non-linear models (interaction terms!) could be used to characterize more complex relationships, as well as different choices for the link function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FkjzD-5etov1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7VHIkBM2G-G"
      },
      "source": [
        "This is a dataset of 70,000 28x28 images, each flattened into a row. To make the flattened rows, each of the images is split into rows. Then the image rows are stacked horizontally. Thus, each column represents a specific pixel location of the original image.\n",
        "\n",
        "$$I=\n",
        "\\overbrace{\\begin{bmatrix}\n",
        "0 & 0 & 0 & \\cdots & 0 & 0 & 0 \\\\\n",
        "\\vdots & & & & & & \\vdots \\\\\n",
        "0 & 0 & 0 & \\cdots & 0 & 0 & 0\n",
        "\\end{bmatrix}}^{28 px}\n",
        "\\to \\left.\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 0 & \\cdots & 0 & 0 & 0 \\\\ \\hline\n",
        "\\vdots & & & & & & \\vdots \\\\ \\hline\n",
        "0 & 0 & 0 & \\cdots & 0 & 0 & 0\n",
        "\\end{bmatrix}\n",
        "\\right\\}28 px \\to\n",
        "\\overbrace{\\begin{bmatrix}\n",
        "0 & 0 & 0 & \\cdots & 0 & 0 & 0 & | & 0 & 0 & 0 & \\cdots & 0 & 0 & 0 & | & \\cdots\n",
        "\\end{bmatrix}}^{28^2 px}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_data = datasets.fetch_openml('mnist_784', version=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQCz9hyT2q46",
        "outputId": "81800464-678e-4bd7-cdb3-881f4ed4c109"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "mnist_data.data.iloc[i, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DonMkUMz3bnj",
        "outputId": "d161d8bd-2a6f-417e-f1fc-962811c34907"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pixel1      0.0\n",
              "pixel2      0.0\n",
              "pixel3      0.0\n",
              "pixel4      0.0\n",
              "pixel5      0.0\n",
              "           ... \n",
              "pixel780    0.0\n",
              "pixel781    0.0\n",
              "pixel782    0.0\n",
              "pixel783    0.0\n",
              "pixel784    0.0\n",
              "Name: 1, Length: 784, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-Fo0T35Ttov2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf17fa5-9d68-4406-aaf2-802e1ad2e17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instance of data labeled '0':\n",
            "\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   51  159 253 159 50  0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   48  238 252 252 252 237 0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   54  227 253 252 239 233 252 57  6   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   10  60  224 252 253 252 202 84  252 253 122 0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   163 252 252 252 253 252 252 96  189 253 167 0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   51  238 253 253 190 114 253 228 47  79  255 168 0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   48  238 252 252 179 12  75  121 21  0   0   253 243 50  0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   38  165 253 233 208 84  0   0   0   0   0   0   253 252 165 0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   7   178 252 240 71  19  28  0   0   0   0   0   0   253 252 195 0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   57  252 252 63  0   0   0   0   0   0   0   0   0   253 252 195 0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   198 253 190 0   0   0   0   0   0   0   0   0   0   255 253 196 0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   76  246 252 112 0   0   0   0   0   0   0   0   0   0   253 252 148 0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   85  252 230 25  0   0   0   0   0   0   0   0   7   135 253 186 12  0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   85  252 223 0   0   0   0   0   0   0   0   7   131 252 225 71  0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   85  252 145 0   0   0   0   0   0   0   48  165 252 173 0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   86  253 225 0   0   0   0   0   0   114 238 253 162 0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   85  252 249 146 48  29  85  178 225 253 223 167 56  0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   85  252 252 252 229 215 252 252 252 196 130 0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   28  199 252 252 253 252 252 233 145 0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   25  128 252 253 252 141 37  0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n",
            "|   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   |\n"
          ]
        }
      ],
      "source": [
        "i = 1\n",
        "print(\"Instance of data labeled '{}':\\n\".format(mnist_data.target[i]))\n",
        "datumi = np.reshape(mnist_data.data.iloc[i, :].values, (28, 28))\n",
        "for row in datumi:\n",
        "    print('|', end='   ')\n",
        "    for pixel in row:\n",
        "        intensity = np.int64(pixel)\n",
        "        print( intensity, end='{}'.format(' ' * (4 - len(str(intensity)))) )\n",
        "    print('|')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_image(data, i, dim=-1):\n",
        "    extracted = []\n",
        "    for j in i:\n",
        "        extracted.append(np.reshape(data.iloc[j, :].values, dim))\n",
        "\n",
        "    return extracted\n",
        "\n",
        "def show_images(data, show):\n",
        "    images = extract_image(data, show, (28, 28))\n",
        "    fig, axes = plt.subplots(1, len(show), figsize=(200/len(show), 10))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.matshow(-images[i], cmap=plt.cm.gray)\n",
        "        ax.set_xticks(())\n",
        "        ax.set_yticks(())"
      ],
      "metadata": {
        "id": "Aw9AMlO-3Mmb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(mnist_data.data, range(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "vuOzjbb830eK",
        "outputId": "e0f119dc-e392-4b5f-cf7c-228e428c59cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist_data.data\n",
        "y = mnist_data.target\n",
        "y.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMkLlf274A5a",
        "outputId": "4e246757-ec15-4714-d29c-4f42836fcf38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5\n",
              "1    0\n",
              "2    4\n",
              "3    1\n",
              "4    9\n",
              "5    2\n",
              "6    1\n",
              "7    3\n",
              "8    1\n",
              "9    4\n",
              "Name: class, dtype: category\n",
              "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WkULurfYtov2",
        "outputId": "c6e9072b-6c27-4f78-ac4a-60a9b872baa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 784)\n",
            "(100, 784)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, train_size=2000, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": false,
        "id": "VPx_B4MCtov4",
        "outputId": "f98977d7-4c21-4735-a9a9-4257f52598a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def output(model, _X_test, _y_test):\n",
        "    print('Classes: {}'.format(model.classes_))\n",
        "\n",
        "    with np.printoptions(precision=3, suppress=True):\n",
        "      print(model.predict_proba(_X_test))\n",
        "\n",
        "    print(\".\\n\"*3)\n",
        "    print('Score for test data: {:.2%}'.format(model.score(_X_test, _y_test)))\n",
        "\n",
        "output(clf, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGDWWRsn55XB",
        "outputId": "90f0f181-6391-4d82-f1ee-48e7df82221f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
            "[[1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.997 0.    0.    0.003 0.    0.   ]\n",
            " [0.    0.    0.    0.    0.996 0.    0.    0.004 0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.998 0.002 0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.999 0.    0.    0.    0.001 0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.008 0.    0.    0.    0.992 0.    0.    0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
            " [0.    0.    0.    0.    0.992 0.    0.001 0.007 0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.975 0.    0.    0.025 0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.081 0.    0.919]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.62  0.379 0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.946 0.054 0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
            " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.996 0.    0.    0.    0.004 0.   ]\n",
            " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.995 0.    0.    0.    0.    0.    0.005 0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.999 0.    0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
            " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.005 0.    0.995]\n",
            " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]]\n",
            ".\n",
            ".\n",
            ".\n",
            "\n",
            "Score for test data: 86.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rJo2YdCItov5",
        "outputId": "5214c1cc-8230-47ec-d719-8fcc8848a051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 784)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[-2.81735115e-05  5.20796603e-05  7.72516771e-05 -8.87873705e-05\n",
            "  3.42006939e-05  1.08967678e-04 -2.88475683e-05  6.96023218e-05\n",
            " -1.87149026e-04 -9.14455527e-06]\n"
          ]
        }
      ],
      "source": [
        "print(clf.coef_.shape)\n",
        "print(clf.coef_) # from doc: coef_ corresponds to outcome 1 (True)\n",
        "print(clf.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEGCKR6ftov5"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSHSokPDtov5"
      },
      "source": [
        "A decision tree is a structured way to make decisions by assigning probabilities to courses of action based on the outcomes of certain events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ofnchStov6"
      },
      "source": [
        "We can imagine that every time we want to make a decision, several options are available to us.\n",
        "\n",
        "![](https://i1.wp.com/www.samtalksml.net/wp-content/uploads/2017/05/image_dt1-1.png?resize=450%2C368&ssl=1)\n",
        "\n",
        "![](http://www.prognoz.com/blog/wp-content/uploads/2016/06/tree.png)\n",
        "\n",
        "![](https://victorzhou.com/media/random-forest-post/decision-tree2-root.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ONZNoTMtov6"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngMfhInRtov6"
      },
      "source": [
        "The problem with decision trees is their tendency to overfit. The fact that apples and grapes appear as leaf nodes multiple times is an example of this problem. For small decision trees, this harms interpretibility. For classification tasks, their generality is harmed when new  data is introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDuYBoBltov7"
      },
      "source": [
        "Random Forest is a method of overcoming the overfitting problem. It creates classification trees which each only see a small portion of the training set, and may even only see a subset of its dimensions. By combining these trees, the variance is reduced significantly while slightly increasing the bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQvD__gGtov7"
      },
      "source": [
        "![](https://miro.medium.com/max/592/1*i0o8mjFfCn-uD79-F1Cqkw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_BzwdJktov7"
      },
      "source": [
        "Random forest will only give importance of the features for classification, but has no analogy to the sign of the beta coefficients. Small magnitude importance means that features have little impact. These importance scores are also invariant to feature scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6MrHdqhQtov7",
        "outputId": "022718ca-4d3a-4b96-b41d-96cc42a464e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xY0n-K2Vtov8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15ca2d7-2e07-4cfb-83af-d39979bd84b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
            "[[0.63 0.   0.03 0.01 0.08 0.02 0.15 0.   0.07 0.01]\n",
            " [0.   0.   0.01 0.01 0.86 0.05 0.01 0.01 0.   0.05]\n",
            " [0.   0.99 0.   0.   0.   0.   0.   0.   0.   0.01]\n",
            " [0.09 0.01 0.57 0.06 0.01 0.09 0.06 0.04 0.06 0.01]\n",
            " [0.06 0.08 0.05 0.05 0.13 0.03 0.07 0.37 0.01 0.15]\n",
            " [0.06 0.01 0.08 0.09 0.21 0.03 0.07 0.13 0.02 0.3 ]\n",
            " [0.   0.   0.   0.01 0.   0.01 0.   0.98 0.   0.  ]\n",
            " [0.   0.95 0.   0.01 0.   0.02 0.   0.   0.02 0.  ]\n",
            " [0.   0.91 0.02 0.03 0.02 0.   0.01 0.   0.   0.01]\n",
            " [0.   0.02 0.03 0.11 0.01 0.07 0.   0.69 0.04 0.03]\n",
            " [0.   0.97 0.   0.01 0.01 0.   0.   0.   0.01 0.  ]\n",
            " [0.   0.   0.03 0.86 0.   0.07 0.   0.   0.04 0.  ]\n",
            " [0.   0.   0.01 0.01 0.79 0.04 0.   0.05 0.02 0.08]\n",
            " [0.02 0.   0.71 0.02 0.   0.02 0.   0.   0.23 0.  ]\n",
            " [0.01 0.02 0.09 0.06 0.36 0.12 0.15 0.03 0.09 0.07]\n",
            " [0.02 0.   0.01 0.04 0.74 0.01 0.03 0.04 0.05 0.06]\n",
            " [0.06 0.01 0.05 0.   0.06 0.04 0.73 0.01 0.01 0.03]\n",
            " [0.02 0.   0.2  0.02 0.02 0.01 0.02 0.58 0.07 0.06]\n",
            " [0.   0.01 0.09 0.07 0.11 0.06 0.02 0.2  0.15 0.29]\n",
            " [0.03 0.   0.02 0.8  0.   0.07 0.   0.   0.04 0.04]\n",
            " [0.   0.01 0.   0.01 0.02 0.09 0.   0.86 0.   0.01]\n",
            " [0.91 0.   0.   0.   0.02 0.01 0.05 0.   0.01 0.  ]\n",
            " [0.01 0.01 0.02 0.22 0.04 0.59 0.02 0.01 0.02 0.06]\n",
            " [0.01 0.02 0.01 0.05 0.11 0.04 0.02 0.27 0.   0.47]\n",
            " [0.05 0.01 0.09 0.02 0.06 0.09 0.56 0.01 0.06 0.05]\n",
            " [0.03 0.01 0.04 0.09 0.05 0.64 0.02 0.   0.06 0.06]\n",
            " [0.03 0.   0.11 0.03 0.   0.01 0.69 0.01 0.11 0.01]\n",
            " [0.05 0.   0.04 0.   0.64 0.05 0.09 0.03 0.01 0.09]\n",
            " [0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
            " [0.03 0.03 0.03 0.01 0.63 0.02 0.02 0.05 0.02 0.16]\n",
            " [0.02 0.01 0.04 0.48 0.05 0.14 0.01 0.02 0.18 0.05]\n",
            " [0.03 0.   0.05 0.09 0.05 0.61 0.04 0.02 0.06 0.05]\n",
            " [0.98 0.   0.01 0.   0.   0.   0.   0.   0.01 0.  ]\n",
            " [0.   0.68 0.05 0.05 0.04 0.01 0.   0.1  0.06 0.01]\n",
            " [0.   0.   0.   0.   0.77 0.   0.03 0.02 0.   0.18]\n",
            " [0.01 0.06 0.11 0.05 0.2  0.09 0.32 0.01 0.1  0.05]\n",
            " [0.02 0.01 0.12 0.65 0.02 0.08 0.   0.01 0.09 0.  ]\n",
            " [0.   0.01 0.   0.02 0.13 0.04 0.   0.04 0.02 0.74]\n",
            " [0.05 0.02 0.06 0.02 0.35 0.01 0.1  0.15 0.1  0.14]\n",
            " [0.08 0.02 0.07 0.03 0.08 0.48 0.1  0.05 0.07 0.02]\n",
            " [0.01 0.08 0.05 0.14 0.09 0.05 0.   0.05 0.27 0.26]\n",
            " [0.86 0.02 0.   0.02 0.01 0.03 0.01 0.05 0.   0.  ]\n",
            " [0.01 0.01 0.02 0.17 0.2  0.12 0.03 0.11 0.01 0.32]\n",
            " [0.08 0.   0.15 0.01 0.07 0.   0.59 0.05 0.03 0.02]\n",
            " [0.93 0.   0.02 0.   0.01 0.   0.04 0.   0.   0.  ]\n",
            " [0.   0.   0.03 0.04 0.09 0.02 0.03 0.1  0.   0.69]\n",
            " [0.19 0.02 0.05 0.03 0.09 0.09 0.01 0.39 0.01 0.12]\n",
            " [0.09 0.04 0.05 0.13 0.01 0.51 0.05 0.   0.08 0.04]\n",
            " [0.03 0.   0.04 0.02 0.   0.01 0.   0.9  0.   0.  ]\n",
            " [0.   0.98 0.02 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.69 0.01 0.05 0.04 0.03 0.06 0.03 0.01 0.07 0.01]\n",
            " [0.   0.84 0.01 0.03 0.   0.04 0.   0.07 0.01 0.  ]\n",
            " [0.04 0.01 0.04 0.54 0.03 0.13 0.01 0.01 0.12 0.07]\n",
            " [0.05 0.07 0.05 0.1  0.16 0.38 0.08 0.05 0.05 0.01]\n",
            " [0.07 0.   0.03 0.21 0.02 0.47 0.03 0.03 0.05 0.09]\n",
            " [0.7  0.   0.04 0.02 0.01 0.07 0.04 0.01 0.08 0.03]\n",
            " [0.05 0.02 0.01 0.14 0.01 0.64 0.02 0.04 0.03 0.04]\n",
            " [0.89 0.   0.01 0.02 0.   0.03 0.01 0.02 0.02 0.  ]\n",
            " [0.38 0.02 0.04 0.07 0.05 0.09 0.04 0.09 0.1  0.12]\n",
            " [0.02 0.02 0.06 0.51 0.08 0.14 0.   0.04 0.07 0.06]\n",
            " [0.08 0.   0.13 0.   0.08 0.05 0.   0.57 0.05 0.04]\n",
            " [0.13 0.07 0.11 0.15 0.12 0.15 0.15 0.04 0.08 0.  ]\n",
            " [0.   0.78 0.02 0.04 0.01 0.07 0.04 0.   0.02 0.02]\n",
            " [0.01 0.23 0.04 0.   0.02 0.05 0.02 0.02 0.6  0.01]\n",
            " [0.01 0.   0.07 0.03 0.43 0.01 0.14 0.05 0.04 0.22]\n",
            " [0.1  0.02 0.03 0.01 0.08 0.5  0.04 0.02 0.15 0.05]\n",
            " [0.01 0.   0.82 0.04 0.   0.   0.   0.05 0.08 0.  ]\n",
            " [0.02 0.   0.02 0.02 0.01 0.02 0.   0.01 0.89 0.01]\n",
            " [0.07 0.   0.29 0.11 0.1  0.16 0.04 0.01 0.12 0.1 ]\n",
            " [0.   0.   0.   0.03 0.82 0.01 0.03 0.01 0.02 0.08]\n",
            " [0.   0.03 0.06 0.03 0.32 0.05 0.12 0.07 0.07 0.25]\n",
            " [0.01 0.   0.   0.   0.72 0.03 0.05 0.   0.05 0.14]\n",
            " [0.   0.   0.06 0.69 0.01 0.14 0.   0.   0.09 0.01]\n",
            " [0.   0.01 0.07 0.07 0.34 0.06 0.03 0.1  0.22 0.1 ]\n",
            " [0.   0.   0.01 0.35 0.02 0.23 0.02 0.13 0.09 0.15]\n",
            " [0.02 0.02 0.01 0.09 0.51 0.09 0.03 0.01 0.08 0.14]\n",
            " [0.05 0.05 0.02 0.07 0.08 0.55 0.11 0.02 0.02 0.03]\n",
            " [0.65 0.   0.04 0.05 0.01 0.07 0.09 0.   0.09 0.  ]\n",
            " [0.01 0.12 0.24 0.12 0.03 0.03 0.04 0.19 0.17 0.05]\n",
            " [0.01 0.   0.02 0.   0.86 0.   0.   0.   0.01 0.1 ]\n",
            " [0.71 0.   0.03 0.05 0.01 0.05 0.11 0.   0.02 0.02]\n",
            " [0.03 0.01 0.07 0.1  0.02 0.6  0.05 0.   0.08 0.04]\n",
            " [0.03 0.01 0.13 0.1  0.09 0.18 0.05 0.08 0.09 0.24]\n",
            " [0.82 0.   0.03 0.02 0.01 0.02 0.04 0.03 0.02 0.01]\n",
            " [0.   0.01 0.01 0.01 0.71 0.02 0.04 0.05 0.03 0.12]\n",
            " [0.01 0.   0.02 0.06 0.14 0.02 0.   0.04 0.01 0.7 ]\n",
            " [0.   0.   0.01 0.01 0.04 0.   0.   0.84 0.03 0.07]\n",
            " [0.41 0.04 0.27 0.06 0.03 0.06 0.04 0.03 0.04 0.02]\n",
            " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.09 0.05 0.1  0.06 0.15 0.15 0.12 0.05 0.22 0.01]\n",
            " [0.   0.91 0.   0.02 0.02 0.   0.   0.01 0.03 0.01]\n",
            " [0.69 0.   0.1  0.01 0.04 0.03 0.08 0.01 0.   0.04]\n",
            " [0.   0.11 0.05 0.01 0.03 0.01 0.01 0.69 0.03 0.06]\n",
            " [0.05 0.01 0.05 0.25 0.02 0.48 0.06 0.02 0.06 0.  ]\n",
            " [0.06 0.01 0.07 0.01 0.41 0.   0.2  0.03 0.05 0.16]\n",
            " [0.73 0.   0.05 0.04 0.01 0.07 0.04 0.03 0.03 0.  ]\n",
            " [0.02 0.01 0.07 0.   0.48 0.02 0.15 0.05 0.03 0.17]\n",
            " [0.01 0.02 0.04 0.02 0.46 0.03 0.18 0.06 0.09 0.09]\n",
            " [0.03 0.   0.01 0.   0.02 0.04 0.02 0.86 0.   0.02]\n",
            " [0.01 0.2  0.06 0.03 0.02 0.03 0.   0.04 0.6  0.01]]\n",
            ".\n",
            ".\n",
            ".\n",
            "\n",
            "Score for test data: 92.00%\n"
          ]
        }
      ],
      "source": [
        "output(rfc, X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
